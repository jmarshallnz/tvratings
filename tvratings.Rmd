---
title: "TV viewership in NZ news and current affairs"
author: "Jonathan Marshall"
date: "12 April 2015"
output: html_document
---

Below is a plot of the trend in TV viewership numbers from mid-February 2012 through to mid-April 2015 for the larger news and current affairs shows in New Zealand, namely One News, Close Up, Seven Sharp, 3 News and Campbell Live.  Of interest:

* There is strong seasonality in the viewership of the TV One shows which are higher in the winter months.
* The viewership of the 7pm show on TV One (Close Up or Seven Sharp) is highly correlated with One News, suggesting these programs share viewers.
* The current viewership for Campbell Live is similar to it's viewership at the end of 2012 and beginning of 2013.
* Campbell Live's viewership doesn't tend to correlate as strongly with the viewership of 3 News compared to the shows on TV One.

The data are sourced from Nielsen's Television Audience Measurement, All 5+ by scraping the [Throng NZ website](http://www.throng.co.nz).  A useful reference for the Nielsen TAM data is available [here](http://images.tvnz.co.nz/tvnz_images/planit/opportunities/week_24/measurement_of_tv.pdf). Due to the website scraping, **there are several caveats with these data** which are outlined below the plot. 

A smooth curve for the average of the ratings data for each show by fitting a generalised additive model to the data that allows a smooth curve where the amount of smoothing adapts to the way the data are changing. Essentially the model trades off fitting the data perfectly (and thus producing a very wiggly curve) against reducing the amount of noise (and producing a very smooth curve that doesn't fit the data well). A balance between these two extremes produces a curve that isn't too wiggly but still captures the variation in the data.

The analysis and this report were created using [RStudio](http://rstudio.com). The source code for the plot (using the [dygraphs package](https://github.com/rstudio/dygraphs)), the website scraping, and this report are available on [github](https://github.com/jmarshallnz/tvratings).

```{r, echo=FALSE, fig.width=8, fig.height=5, warning=F, message=F}
library(splines)
library(mgcv)
library(dplyr)
library(dygraphs)
library(htmlwidgets)

ratings <- read.csv("news_current_affairs.csv")

ratings$Date <- as.Date(ratings$Date)

# grab show data
show_cols <- c(4,2,3,5,1)
ratings[,1:5] <- ratings[,show_cols]
names(ratings)[1:5] <- names(ratings)[show_cols]
show_names <- gsub("\\.", " ", gsub("^X([0-9])+", "\\1", names(ratings)))

# fit a GAM model to each show
for (i in seq_along(show_cols)) {
  # smooth
  g <- gam(ratings[,i] ~ s(as.numeric(Date), bs="ad"), data=ratings)
  first_date <- min(ratings$Date[!is.na(ratings[,i])])
  last_date  <- max(ratings$Date[!is.na(ratings[,i])])
  date_range <- seq(first_date, to=last_date, by=1)
  y <- predict(g, newdata=data.frame(Date=date_range), se.fit=T)

  # add these as additional columns in the data frame
  ratings[ratings$Date %in% date_range,paste0("fit.", i, ".mean")] <- y$fit
  ratings[ratings$Date %in% date_range,paste0("fit.", i, ".se")] <- y$se.fit*1.96

  # our plotting handler hack relies on 0's in place of NAs where we want
  # to render the model fit, else the custom bar plotter in dygraphs doesn't allow
  # the error bars (which are hacked to be fit + se) to be drawn
  
  # ideally this would be done by a custom dataHandler in dygraphs
  ratings[ratings$Date %in% date_range,i] <- ifelse(is.na(ratings[ratings$Date %in% date_range,i]), 0, ratings[ratings$Date %in% date_range,i])
}

cols <- data.frame(r=c(203,73,254,52,163),g=c(15,175,74,135,47),b=c(21,156,75,191,34))
cols <- cols[c(1,3,5,4,2),]
#cols <- cols[show_cols[c(2,3,5,1,4)],]

# compute faded colour (fade to white)
fade_colour <- function(col, alpha) {
  faded <- (255-alpha)/255 * 255 + alpha/255 * col
  rgb(faded$r, faded$g, faded$b, maxColorValue=255)
}

# value formatter for labels
value_fmt <- "function(y, opts, series_name) {
  if (y != 0)
    return y.toFixed(0);
  return '-';
}"

date_fmt <- "function(x, opts, series_name) {
  day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
  month_names = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']
  var date = new Date(x);
  return day_names[date.getDay()] + ', ' + date.getDate() + ' ' + month_names[date.getMonth()] + ' ' + (date.getYear()+1900);
}"

# point callback so that our '0' values don't render
point_cb <- "function(g, seriesName, canvasContext, cx, cy, color, pointSize) {
  var area = g.layout_.getPlotArea();
  if (cy != area.y + area.h)
    Dygraph.Circles.DEFAULT(g, seriesName, canvasContext, cx, cy, color, pointSize);
}"

# plotter for the series
plot_se <- "function(e) {
  // create new points for data and model fit
  var newFit = [];
  var newData = [];
  for (var i = 0; i < e.points.length; i++) {
    var o = e.points[i];
    newData.push({
      canvasx:  o.canvasx,
      canvasy:  o.yval == 0 ? NaN : o.canvasy,
      x:        o.x,
      y:        o.yval == 0 ? NaN : o.y
    })
    newFit.push({
      canvasx:  o.canvasx,
      canvasy:  e.plotArea.h * o.y_top + e.plotArea.y,
      x:        o.x,
      y:        o.y_top,
      y_bottom: o.y_top + (1-o.y_bottom),
      y_top:    o.y_top - (1-o.y_bottom)
    })
  }
  // call the base functions
  var f = {
        points: newData,
        setName: e.setName,
        drawingContext: e.drawingContext,
        color: e.color,
        strokeWidth: e.strokeWidth,
        dygraph: e.dygraph,
        axis: e.axis,
        plotArea: e.plotArea,
        seriesIndex: e.seriesIndex,
        seriesCount: e.seriesCount,
        singleSeriesName: e.singleSeriesName,
        allSeriesPoints: e.allSeriesPoints
  };
  Dygraph.Plotters.linePlotter(f);
  f.points = newFit;
  f.strokeWidth = 2;
  Dygraph.Plotters.errorPlotter(f);
  Dygraph.Plotters.linePlotter(f);
}"

cols_fit  <- rgb(cols$r, cols$g, cols$b, maxColorValue=255)
cols_data <- fade_colour(cols, 160)

max_viewers <- 1000001 #max(ratings[,show_cols], na.rm=T)

rownames(ratings) <- ratings$Date

# draw the dygraph using a custom plotter for each series
d <- dygraph(data=ratings[,-6], main="Viewership of news and current affairs");
for (i in seq_along(show_cols))
  d <- d %>% dySeries(c(paste0("fit.",i,".mean"), names(ratings)[i], paste0("fit.",i,".se")), label=show_names[i], color=cols_fit[i], strokeWidth=0.5, plotter=JS(plot_se))

xlab <- "<span style='color:#7f7f7f'>General additive model with adaptive smoothing and 95% credible intervals<br>Data source: Nielsen Television Audience Measurement, All 5+ via <a href='http://www.throng.co.nz'>www.throng.co.nz</a></span>"
gray <- rgb(0.5, 0.5, 0.5)
lightgray <- rgb(0.9, 0.9, 0.9)
d %>% dyOptions(fillAlpha=0.4, maxNumberWidth=7) %>%
      dyAxis('x', label=xlab, labelHeight=12, drawGrid=FALSE,
             axisLineColor=gray, axisLabelColor=gray,
             axisLabelFontSize=10, valueFormatter=JS(date_fmt)) %>%
      dyAxis('y', valueRange=c(0, max_viewers),
             axisLineColor=gray, axisLabelColor=gray,
             axisLabelFontSize=10, gridLineColor=lightgray,
             valueFormatter=JS(value_fmt)) %>%
      dyLegend(width=750) %>%
      dyCSS("tvratings.css") %>%
      dyCallbacks(drawHighlightPointCallback = JS(point_cb))
```

Caveats
-------

Due to the method of obtaining the data, there are several sources of error, listed in order of least likely to most likely.

1. There is a small chance of transcription error if the data Nielsen provides requires human interaction to
produce the reports on [Throng NZ](http://www.throng.co.nz). If the reports on ThrongNZ are automated, then
no such errors are likely.

2. The data published on [Throng NZ](http://www.throng.co.nz) are incomplete in that not all
ratings days are present.  This is unlikely to cause much trouble
unless the days that are missing are the days a particular show does
very well or very poorly (i.e. not missing completely at random).

3. The data published on [Throng NZ](http://www.throng.co.nz) are incomplete in that they
publish primarily information on the top performing shows in a particular evening.
This can cause some specific shows to not show up on all nights.
Crucially, this is more likely to occur if the show in question has a
poor ratings evening (e.g. if Campbell Live does poorly one evening,
then it may not be among the top ratings across or channels, or even
among the top ratings on TV3).  This also applies to repeats on TV3+1.
Thus, we may be overestimating the average viewership for a show that
isn't as popular as One News or 3 News due to poor ratings not
showing up.

4. The scraping technique may miss to grab the numbers for a show on
some evenings, even though the information is there.  Basically what
happens is the HTML source for the webpage is parsed with a regular
expression to pick out certain bits that contain the info we want.  If
for some reason the webpage layout is slightly different, or there is
a typo in the show name, an extra space where it shouldn't be or some
such, then we may miss it.  Or, more likely, the code has a bug. This
may not happen completely at random (e.g. it may be associated with high or low show rates).

The above situations are most likely minimal in the graph produced above.
Nonetheless, a more thorough analysis would want to use a better data
source such as Nielsen directly, or perhaps whatever
raw data [Throng NZ](http://www.throng.co.nz) may have.